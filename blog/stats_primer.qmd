---
title: "Discovering Statistics: An Interactive Primer"
subtitle: "Building Intuition for Basic Concepts"
description: "This primer uses hands on examples to explore essential statistical concepts including probability, distributions, hypothesis testing, and regression analysis."
author: "Alasdair Warwick"
date: 2025-01-02
categories: [Probability, Start here, Slides]
editor: source
format:
    revealjs:
        theme: simple
        transition: fade
        transition-speed: fast
        chalkboard: true
        smaller: true
        scrollable: true
        code-fold: true
        code-link: true
        echo: true
        logo: "../stats-favicon.png"
        include-in-header:
            - text: |
                <script src="https://cdn.plot.ly/plotly-2.20.0.min.js"></script>
---

## Contents

- ⁠Single sample: probability basics - normal distribution and binomial (coins)
- ⁠⁠2 samples: normal and chi square
- Adjusting for confounders - (stratifying) & linear regression. Logistic regression

## Normal distribution

::: {.column-page}
<iframe src="../resources/normal-vs-t-distribution.html" width="100%" height="570px" frameBorder="0"></iframe>
:::

::: {.notes}

**Try this**

1. Start with default settings (mean=0, SD=1, n=30)
2. Reduce sample size to n=5 and observe how t-distribution tails become heavier
3. Increase sample size to n=100 and see how t-distribution converges to normal
4. Adjust mean and standard deviation to see how both distributions shift and scale
5. Compare the width of confidence intervals (dashed lines) between distributions

**Notes**

- The normal distribution (blue) is symmetric and bell-shaped
- The t-distribution (red) has heavier tails than the normal distribution
- As sample size increases, the t-distribution approaches the normal distribution
- The choice between them depends on whether the population standard deviation is known:
    - Normal distribution: Used when population standard deviation is known (rare in practice)
    - t-distribution: Used when estimating standard deviation from sample data (most common)
    - t-distribution accounts for added uncertainty in standard deviation estimate

**Equations**

The mean ($\mu$) and standard deviation ($\sigma$) are calculated as follows:

- Mean ($\mu$): 
$$ \mu = \frac{\sum_{i=1}^{n} x_i}{n} $$

- Standard Deviation (σ): 
$$ \sigma = \sqrt{\frac{\sum_{i=1}^{n} (x_i - \mu)^2}{n}} $$

Where:

- $x_i$ represents each individual data point
- $n$ is the number of data points

:::

## Coin Flip Simulation

This simulation demonstrates the binomial distribution through repeated coin flips.

::: {.column-page}
<iframe src="../resources/coin-flip.html" width="100%" height="500px" frameBorder="0"></iframe>
:::

::: {.notes}

::: {.callout-tip}
## Try this

- Flip a coin 10 times
- Click 'Play' to repeat the experiment (select the 'Multi-flip' check box to perform 10 coin flips each time)
:::

:::

## Binomial distribution

::: {.column-page}
<iframe src="../resources/binomial-simulation.html" width="100%" height="500px" frameBorder="0"></iframe>
:::

## Binomial distribution {background-color="lightblue" visibility="uncounted"}

The binomial distribution is given by the formula:

$$ P(X = k) = \binom{n}{k} p^k (1-p)^{n-k} $$

Where:

- $P(X = k)$ is the probability of getting exactly $k$ successes in $n$ trials.
- $\binom{n}{k}$ is the binomial coefficient, which represents the number of ways to choose $k$ successes from $n$ trials.
- $p$ is the probability of success on a single trial.
- $(1-p)$ is the probability of failure on a single trial.

## Sampling variation

::: {.column-page}
<iframe src="../resources/sampling-variation.html" width="100%" height="550px" frameBorder="0"></iframe>
:::

## Comparing 2 samples

::: {.column-page}
<iframe src="../resources/compare-means.html" width="100%" height="560px" frameBorder="0"></iframe>
:::

## Next slides

To do

```{python}
print("Hi")
```
